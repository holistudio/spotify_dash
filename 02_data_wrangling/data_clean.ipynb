{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846c74de",
   "metadata": {},
   "source": [
    "# Clean Combined Dataset\n",
    "\n",
    "Remove as many \"non-vibe\" words from playlist names and get word occurence counts for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4630009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052a07d",
   "metadata": {},
   "source": [
    "## Load combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deda4eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>playlist_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7k9GuJYLp2AzqokyEdwEw2</td>\n",
       "      <td>Ross Copperman</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>56</td>\n",
       "      <td>205594</td>\n",
       "      <td>False</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>78.899</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>high, high, AUTUMN, Vampire Diaries, sleep, i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1KHdq8NK9QxnGjdXb55NiG</td>\n",
       "      <td>Landon Pigg</td>\n",
       "      <td>The Boy Who Never</td>\n",
       "      <td>Falling in Love at a Coffee Shop</td>\n",
       "      <td>58</td>\n",
       "      <td>244986</td>\n",
       "      <td>False</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.561</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>83.457</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Say You Won't Let Go, mellow, Dance, Chillin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2qLMf6TuEC3ruGJg4SMMN6</td>\n",
       "      <td>Jason Mraz;Colbie Caillat</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>Lucky</td>\n",
       "      <td>68</td>\n",
       "      <td>189613</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>130.088</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3S0OXQeoh0w6AY8WQVckRW</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>75</td>\n",
       "      <td>242946</td>\n",
       "      <td>False</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>150.960</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>tb, Catchy Songs, #boostyourrun, go to, Atlas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5TvE3pk05pyFIGdSY9j4DJ</td>\n",
       "      <td>A Great Big World;Christina Aguilera</td>\n",
       "      <td>Is There Anybody Out There? - Track by Track C...</td>\n",
       "      <td>Say Something</td>\n",
       "      <td>70</td>\n",
       "      <td>229400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>141.284</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>~Rando~, go to, Solitude, Acoustic, happy, yo,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                               artists  \\\n",
       "0  7k9GuJYLp2AzqokyEdwEw2                        Ross Copperman   \n",
       "1  1KHdq8NK9QxnGjdXb55NiG                           Landon Pigg   \n",
       "2  2qLMf6TuEC3ruGJg4SMMN6             Jason Mraz;Colbie Caillat   \n",
       "3  3S0OXQeoh0w6AY8WQVckRW                            Jason Mraz   \n",
       "4  5TvE3pk05pyFIGdSY9j4DJ  A Great Big World;Christina Aguilera   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Hunger   \n",
       "1                                  The Boy Who Never   \n",
       "2                We Sing. We Dance. We Steal Things.   \n",
       "3                We Sing. We Dance. We Steal Things.   \n",
       "4  Is There Anybody Out There? - Track by Track C...   \n",
       "\n",
       "                         track_name popularity duration_ms explicit  \\\n",
       "0                            Hunger         56      205594    False   \n",
       "1  Falling in Love at a Coffee Shop         58      244986    False   \n",
       "2                             Lucky         68      189613    False   \n",
       "3                         I'm Yours         75      242946    False   \n",
       "4                     Say Something         70      229400    False   \n",
       "\n",
       "   danceability  energy key  ...  mode speechiness  acousticness  \\\n",
       "0         0.442   0.632   1  ...     1      0.0295         0.426   \n",
       "1         0.489   0.561   4  ...     1      0.0274         0.200   \n",
       "2         0.625   0.414   0  ...     1      0.0369         0.294   \n",
       "3         0.703   0.444  11  ...     1      0.0417         0.559   \n",
       "4         0.407   0.147   2  ...     1      0.0355         0.857   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \\\n",
       "0          0.004190    0.0735   0.1960   78.899               4    acoustic   \n",
       "1          0.000046    0.1790   0.2380   83.457               3    acoustic   \n",
       "2          0.000000    0.1510   0.6690  130.088               4    acoustic   \n",
       "3          0.000000    0.0973   0.7120  150.960               4    acoustic   \n",
       "4          0.000003    0.0913   0.0765  141.284               3    acoustic   \n",
       "\n",
       "                                      playlist_names  \n",
       "0  high, high, AUTUMN, Vampire Diaries, sleep, i ...  \n",
       "1  Say You Won't Let Go, mellow, Dance, Chillin, ...  \n",
       "2  Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...  \n",
       "3  tb, Catchy Songs, #boostyourrun, go to, Atlas,...  \n",
       "4  ~Rando~, go to, Solitude, Acoustic, happy, yo,...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join('..','..','datasets','tracks_playlist_dataset')\n",
    "\n",
    "df_file_path = os.path.join(dataset_dir,'tracks_playlists_df.pkl')\n",
    "\n",
    "df = pd.read_pickle(df_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48dd5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179120af",
   "metadata": {},
   "source": [
    "## Analyze raw words in playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a8bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c97f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tb',\n",
       " ' Catchy Songs',\n",
       " ' #boostyourrun',\n",
       " ' go to',\n",
       " ' Atlas',\n",
       " ' throwback',\n",
       " ' Acoustic',\n",
       " ' ((chris))',\n",
       " ' throw backs',\n",
       " ' Throwbacks ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68738752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Shower',\n",
       " ' throwback ',\n",
       " ' Stuff I like',\n",
       " ' Classics',\n",
       " ' good times',\n",
       " ' Throwback',\n",
       " ' Songs that never fail to make white people beyond turnt',\n",
       " ' kareoke',\n",
       " ' I love You',\n",
       " ' Lake']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569df4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '5TvE3pk05pyFIGdSY9j4DJ'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e88b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~Rando~',\n",
       " ' go to',\n",
       " ' Solitude',\n",
       " ' Acoustic',\n",
       " ' happy',\n",
       " ' yo',\n",
       " ' my heart',\n",
       " ' Isis',\n",
       " ' Top Hits',\n",
       " ' Mya']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6211d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Depressing songs',\n",
       " ' Easy Listening',\n",
       " ' GRAD',\n",
       " ' L.o.v.e',\n",
       " ' Ballads',\n",
       " ' Inside Out: So Emotional',\n",
       " ' Slow',\n",
       " ' feels',\n",
       " ' Sleep',\n",
       " ' sad times']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2649d01",
   "metadata": {},
   "source": [
    "## Clean playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c2c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles\n",
    "articles = [\n",
    "    \"a\", \"an\", \"the\"\n",
    "]\n",
    "\n",
    "# Common Prepositions\n",
    "# prepositions = [\n",
    "#     \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "#     \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "#     \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "#     \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "#     \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "#     \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"outside\", \"over\", \"past\",\n",
    "#     \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\",\n",
    "#     \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\",\n",
    "#     \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "# ]\n",
    "\n",
    "prepositions = [\n",
    "    \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "    \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "    \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "    \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "    \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "    \"near\", \"of\", \"off\", \"on\", \"onto\", \"outside\", \"over\",\n",
    "    \"per\", \"plus\", \"regarding\", \"round\", \"since\", \"than\", \"through\",\n",
    "    \"to\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "]\n",
    "\n",
    "# Pronouns (personal, possessive, reflexive, demonstrative, relative, interrogative, indefinite)\n",
    "pronouns = [\n",
    "    # Personal\n",
    "    \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\",\n",
    "    # Possessive\n",
    "    \"my\", \"mine\", \"your\", \"yours\", \"his\", \"her\", \"hers\", \"its\", \"our\", \"ours\", \"their\", \"theirs\",\n",
    "    # Reflexive\n",
    "    \"myself\", \"yourself\", \"himself\", \"herself\", \"itself\", \"ourselves\", \"yourselves\", \"themselves\",\n",
    "    # Demonstrative\n",
    "    \"this\", \"that\", \"these\", \"those\",\n",
    "    # Relative\n",
    "    \"who\", \"whom\", \"whose\", \"which\", \"that\",\n",
    "    # Interrogative\n",
    "    \"what\", \"which\", \"who\", \"whom\", \"whose\",\n",
    "    # Indefinite\n",
    "    \"anybody\", \"anyone\", \"anything\", \"each\", \"either\", \"everybody\", \"everyone\", \"everything\",\n",
    "    \"neither\", \"nobody\", \"no one\", \"nothing\", \"one\", \"somebody\", \"someone\", \"something\",\n",
    "    \"both\", \"few\", \"many\", \"several\", \"all\", \"any\", \"most\", \"none\", \"some\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77933892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove synonyms for music/songs\n",
    "# music_stopwords = [\n",
    "#     # General music terms\n",
    "#     \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "#     \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "#     # Album / playlist words\n",
    "#     \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "#     \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "#     # Performance terms\n",
    "#     \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "#     \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "#     # Listening context\n",
    "#     \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "#     \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "#     # Time/context in music\n",
    "#     \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "#     \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "#     # Streaming platform common words\n",
    "#     \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "#     # Music role terms\n",
    "#     \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "#     # Genre meta-words (not actual genres)\n",
    "#     \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "#     \"new\", \"latest\", \"classic\", \"classics\", \"oldies\"\n",
    "# ]\n",
    "\n",
    "music_stopwords = [\n",
    "    # General music terms\n",
    "    \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "    \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "    # Album / playlist words\n",
    "    \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "    \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "    # Performance terms\n",
    "    \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "    \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "    # Listening context\n",
    "    \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "    \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "    # Time/context in music\n",
    "    \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "    \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "    # Streaming platform common words\n",
    "    \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "    # Music role terms\n",
    "    \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "    # Genre meta-words (not actual genres)\n",
    "    \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "    \"new\",\n",
    "\n",
    "    \"spotify\", \"spotifys\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d1c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude feels words\n",
    "\n",
    "# emotion_words = [\n",
    "#     # Feelings (general emotional states)\n",
    "#     \"emotions\", \"sentiments\", \"sensations\", \"reactions\", \"responses\",\n",
    "#     \"passions\", \"affection\", \"affects\", \"attitudes\", \"vibes\",\n",
    "    \n",
    "#     # Mood (emotional tone)\n",
    "#     \"temper\", \"disposition\", \"frame_of_mind\", \"outlook\", \"mindset\",\n",
    "#     \"spirit\", \"tone\", \"ambience\", \"atmosphere\", \"energy\",\n",
    "    \n",
    "#     # Colloquial / modern terms\n",
    "#     \"vibes\", \"aura\", \"feels\", \"headspace\", \"energy\",\n",
    "    \n",
    "#     # More poetic/formal variants\n",
    "#     \"humor\", \"mien\", \"temperament\", \"sentiment\", \"state_of_mind\",\n",
    "#     \"air\", \"bearing\", \"character\"\n",
    "# ]\n",
    "\n",
    "emotion_words = [\n",
    "    \"emotions\", \"emotion\",\n",
    "    \"feelings\", \"feeling\",\n",
    "    \"attitude\", \"attitudes\", \n",
    "    \"vibe\", \"vibes\", \n",
    "    \"feel\", \"feels\", \"headspace\",\n",
    "    \"character\", \"mood\", \"moody\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58362fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_playlist_names(track_id):\n",
    "    # find track_id in DataFrame\n",
    "    filter = df['track_id'] == track_id\n",
    "    row = df[filter].iloc[0]\n",
    "\n",
    "    # get playlist names \n",
    "    playlist_names = row['playlist_names']\n",
    "\n",
    "    # convert to a list\n",
    "    playlist_names = playlist_names.split(',')\n",
    "\n",
    "    # separate into distinct words\n",
    "    playlist_words = []\n",
    "    for name in playlist_names:\n",
    "        # convert to lower case\n",
    "        n = name.lower()\n",
    "\n",
    "        # remove symbols and emojis\n",
    "        n = re.sub(r\"[^\\w\\s]\", \"\", n, flags=re.UNICODE)\n",
    "\n",
    "        # remove all numbers\n",
    "        n = re.sub(r'\\d+', '', n)  # Remove all digits\n",
    "\n",
    "        # remove '_' character\n",
    "        n = n.replace(\"_\", \"\")\n",
    "        \n",
    "        # split based on spaces\n",
    "        n = n.split(' ')\n",
    "        \n",
    "        for word in n:\n",
    "            # exclude articles, prepositions, pronouns\n",
    "            exc0 = len(word) <= 2\n",
    "            exc1 = word in articles\n",
    "            exc2 = word in prepositions\n",
    "            exc3 = word in pronouns\n",
    "\n",
    "            # exclude music stop words\n",
    "            exc4 = word in music_stopwords\n",
    "\n",
    "            # exclude emotion words\n",
    "            exc5 = word in emotion_words\n",
    "\n",
    "            word_ok = not (exc0 or exc1 or exc2 or exc3 or exc4 or\n",
    "                           exc5)\n",
    "            \n",
    "            if word_ok:\n",
    "                playlist_words.append(word)\n",
    "\n",
    "    return playlist_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423ea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id=track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc9aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure',\n",
       " 'love',\n",
       " 'chill']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a6201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential',\n",
       " 'hmmmm',\n",
       " 'alternative',\n",
       " 'jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'let',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3410580",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id='5TvE3pk05pyFIGdSY9j4DJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e0fcc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure',\n",
       " 'love',\n",
       " 'chill']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff4372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential',\n",
       " 'hmmmm',\n",
       " 'alternative',\n",
       " 'jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'let',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a075352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10097"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(playlist_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "102c5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1984"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(playlist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c78475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove 's' from plural forms of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0354f9",
   "metadata": {},
   "source": [
    "## Get word bin counts for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0704aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each track_id\n",
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "\n",
    "# get clean playlist words\n",
    "playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "# get unique playlist words\n",
    "unique_words = set(playlist_words)\n",
    "\n",
    "# create a dictionary with each unique word as a key with value = 0\n",
    "word_bins = {}\n",
    "for word in unique_words:\n",
    "    word_bins[word] = 0\n",
    "\n",
    "# go through the clean playlist words and tabulate using the dictionary\n",
    "for word in playlist_words:\n",
    "    word_bins[word] += 1\n",
    "\n",
    "# convert into a list of words sorted by bin count\n",
    "sorted_items = sorted(word_bins.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d843b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chill', 881),\n",
       " ('wedding', 682),\n",
       " ('love', 659),\n",
       " ('throwback', 656),\n",
       " ('good', 577),\n",
       " ('throwbacks', 341),\n",
       " ('happy', 327),\n",
       " ('summer', 285),\n",
       " ('pop', 266),\n",
       " ('car', 250),\n",
       " ('party', 246),\n",
       " ('beach', 207),\n",
       " ('old', 201),\n",
       " ('road', 188),\n",
       " ('oldies', 165),\n",
       " ('sing', 152),\n",
       " ('dinner', 146),\n",
       " ('trip', 145),\n",
       " ('shower', 145),\n",
       " ('mellow', 140)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "815d2f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('woooo', 1),\n",
       " ('carr', 1),\n",
       " ('releases', 1),\n",
       " ('romanticonas', 1),\n",
       " ('julia', 1),\n",
       " ('jamie', 1),\n",
       " ('mind', 1),\n",
       " ('carrie', 1),\n",
       " ('try', 1),\n",
       " ('rhianna', 1),\n",
       " ('fluffy', 1),\n",
       " ('drugs', 1),\n",
       " ('zombie', 1),\n",
       " ('germany', 1),\n",
       " ('roots', 1),\n",
       " ('monster', 1),\n",
       " ('facu', 1),\n",
       " ('yosemite', 1),\n",
       " ('dutch', 1),\n",
       " ('pipe', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b03ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2510"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fad2b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.025998\n",
      "1.01%, 0:00:02.170972\n",
      "2.01%, 0:00:02.812826\n",
      "3.01%, 0:00:03.211339\n",
      "4.01%, 0:00:07.701607\n",
      "5.00%, 0:00:11.265274\n",
      "6.02%, 0:00:14.290696\n",
      "7.01%, 0:00:15.973813\n",
      "8.01%, 0:00:16.422080\n",
      "9.01%, 0:00:16.691721\n",
      "10.00%, 0:00:16.822822\n",
      "11.00%, 0:00:16.978660\n",
      "12.02%, 0:00:17.178914\n",
      "13.01%, 0:00:17.313546\n",
      "14.01%, 0:00:18.723872\n",
      "15.01%, 0:00:21.780191\n",
      "16.00%, 0:00:23.116883\n",
      "17.00%, 0:00:23.710405\n",
      "18.02%, 0:00:23.866474\n",
      "19.01%, 0:00:25.255869\n",
      "20.01%, 0:00:26.218463\n",
      "21.01%, 0:00:26.720802\n",
      "22.00%, 0:00:26.973535\n",
      "23.00%, 0:00:27.057361\n",
      "24.02%, 0:00:27.139159\n",
      "25.01%, 0:00:27.889536\n",
      "26.01%, 0:00:28.069822\n",
      "27.01%, 0:00:28.238911\n",
      "28.00%, 0:00:28.617941\n",
      "29.00%, 0:00:31.592401\n",
      "30.01%, 0:00:38.270855\n",
      "31.01%, 0:00:43.887788\n",
      "32.01%, 0:00:44.266251\n",
      "33.01%, 0:00:44.389590\n",
      "34.00%, 0:00:44.786827\n",
      "35.00%, 0:00:45.216602\n",
      "36.01%, 0:00:46.841511\n",
      "37.01%, 0:00:47.738942\n",
      "38.01%, 0:00:48.991409\n",
      "39.01%, 0:00:49.249579\n",
      "40.00%, 0:00:49.542096\n",
      "41.00%, 0:00:50.011321\n",
      "42.01%, 0:00:53.798842\n",
      "43.01%, 0:00:58.452253\n",
      "44.01%, 0:00:59.620477\n",
      "45.01%, 0:01:02.557448\n",
      "46.00%, 0:01:03.742421\n",
      "47.00%, 0:01:07.202989\n",
      "48.01%, 0:01:09.349179\n",
      "49.01%, 0:01:10.110276\n",
      "50.01%, 0:01:10.649899\n",
      "51.01%, 0:01:11.115344\n",
      "52.00%, 0:01:11.255512\n",
      "53.02%, 0:01:11.617217\n",
      "54.01%, 0:01:13.830727\n",
      "55.01%, 0:01:15.762026\n",
      "56.01%, 0:01:16.954942\n",
      "57.01%, 0:01:17.556813\n",
      "58.00%, 0:01:18.207076\n",
      "59.02%, 0:01:18.456350\n",
      "60.01%, 0:01:18.552590\n",
      "61.01%, 0:01:23.223612\n",
      "62.01%, 0:01:25.646061\n",
      "63.00%, 0:01:27.079070\n",
      "64.00%, 0:01:30.133007\n",
      "65.02%, 0:01:30.835857\n",
      "66.01%, 0:01:31.142569\n",
      "67.01%, 0:01:34.336953\n",
      "68.01%, 0:01:34.957609\n",
      "69.00%, 0:01:35.088569\n",
      "70.00%, 0:01:37.742074\n",
      "71.02%, 0:01:37.960388\n",
      "72.01%, 0:01:40.490494\n",
      "73.01%, 0:01:41.260308\n",
      "74.01%, 0:01:41.663900\n",
      "75.00%, 0:01:43.248290\n",
      "76.00%, 0:01:43.477574\n",
      "77.02%, 0:01:43.593926\n",
      "78.01%, 0:01:43.699729\n",
      "79.01%, 0:01:44.664336\n",
      "80.01%, 0:01:45.932177\n",
      "81.00%, 0:01:46.465330\n",
      "82.00%, 0:01:46.696776\n",
      "83.01%, 0:01:46.848043\n",
      "84.01%, 0:01:46.952977\n",
      "85.01%, 0:01:47.071732\n",
      "86.01%, 0:01:47.153095\n",
      "87.00%, 0:01:47.331367\n",
      "88.00%, 0:01:48.870876\n",
      "89.01%, 0:01:50.373008\n",
      "90.01%, 0:01:50.573265\n",
      "91.01%, 0:01:50.999620\n",
      "92.01%, 0:01:53.667238\n",
      "93.00%, 0:01:53.929694\n",
      "94.00%, 0:01:55.208451\n",
      "95.01%, 0:01:57.438564\n",
      "96.01%, 0:01:58.451816\n",
      "97.01%, 0:01:59.129127\n",
      "98.01%, 0:02:00.777950\n",
      "99.00%, 0:02:02.948640\n",
      "100.00%, 0:02:04.534098\n"
     ]
    }
   ],
   "source": [
    "# Figure out how many unique words are there in all playlists for all tracks\n",
    "global_words = []\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p=0\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    for w in unique_words:\n",
    "        if w not in global_words:\n",
    "            global_words.append(w)\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c374e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9276"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f0250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f3ca3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.012398\n",
      "1.01%, 0:00:01.537522\n",
      "2.01%, 0:00:01.959491\n",
      "3.01%, 0:00:02.194529\n",
      "4.01%, 0:00:04.988541\n",
      "5.00%, 0:00:07.241069\n",
      "6.02%, 0:00:09.058288\n",
      "7.01%, 0:00:10.045802\n",
      "8.01%, 0:00:10.303630\n",
      "9.01%, 0:00:10.463037\n",
      "10.00%, 0:00:10.544289\n",
      "11.00%, 0:00:10.648051\n",
      "12.02%, 0:00:10.774266\n",
      "13.01%, 0:00:10.867698\n",
      "14.01%, 0:00:11.775327\n",
      "15.01%, 0:00:13.680056\n",
      "16.00%, 0:00:14.495590\n",
      "17.00%, 0:00:14.853865\n",
      "18.02%, 0:00:14.946602\n",
      "19.01%, 0:00:15.808863\n",
      "20.01%, 0:00:16.352659\n",
      "21.01%, 0:00:16.640161\n",
      "22.00%, 0:00:16.786814\n",
      "23.00%, 0:00:16.852774\n",
      "24.02%, 0:00:16.909767\n",
      "25.01%, 0:00:17.363418\n",
      "26.01%, 0:00:17.466891\n",
      "27.01%, 0:00:17.566813\n",
      "28.00%, 0:00:17.799689\n",
      "29.00%, 0:00:19.885303\n",
      "30.01%, 0:00:24.361873\n",
      "31.01%, 0:00:27.993468\n",
      "32.01%, 0:00:28.211191\n",
      "33.01%, 0:00:28.294918\n",
      "34.00%, 0:00:28.545528\n",
      "35.00%, 0:00:28.778635\n",
      "36.01%, 0:00:29.816474\n",
      "37.01%, 0:00:30.361245\n",
      "38.01%, 0:00:31.250346\n",
      "39.01%, 0:00:31.452864\n",
      "40.00%, 0:00:31.596990\n",
      "41.00%, 0:00:31.851783\n",
      "42.01%, 0:00:34.184873\n",
      "43.01%, 0:00:36.918444\n",
      "44.01%, 0:00:37.538928\n",
      "45.01%, 0:00:39.346070\n",
      "46.00%, 0:00:40.072606\n",
      "47.00%, 0:00:42.378656\n",
      "48.01%, 0:00:43.678852\n",
      "49.01%, 0:00:44.048126\n",
      "50.01%, 0:00:44.340031\n",
      "51.01%, 0:00:44.594061\n",
      "52.00%, 0:00:44.680715\n",
      "53.02%, 0:00:44.864617\n",
      "54.01%, 0:00:46.150008\n",
      "55.01%, 0:00:47.313115\n",
      "56.01%, 0:00:47.998001\n",
      "57.01%, 0:00:48.343157\n",
      "58.00%, 0:00:48.719912\n",
      "59.02%, 0:00:48.865643\n",
      "60.01%, 0:00:48.919404\n",
      "61.01%, 0:00:52.214803\n",
      "62.01%, 0:00:53.770597\n",
      "63.00%, 0:00:54.676364\n",
      "64.00%, 0:00:56.525318\n",
      "65.02%, 0:00:56.945829\n",
      "66.01%, 0:00:57.127729\n",
      "67.01%, 0:00:59.355062\n",
      "68.01%, 0:00:59.799768\n",
      "69.00%, 0:00:59.882178\n",
      "70.00%, 0:01:01.702270\n",
      "71.02%, 0:01:01.831371\n",
      "72.01%, 0:01:03.399358\n",
      "73.01%, 0:01:03.885775\n",
      "74.01%, 0:01:04.134342\n",
      "75.00%, 0:01:05.032791\n",
      "76.00%, 0:01:05.161792\n",
      "77.02%, 0:01:05.248947\n",
      "78.01%, 0:01:05.318718\n",
      "79.01%, 0:01:05.849683\n",
      "80.01%, 0:01:06.553640\n",
      "81.00%, 0:01:06.820927\n",
      "82.00%, 0:01:06.962793\n",
      "83.01%, 0:01:07.047871\n",
      "84.01%, 0:01:07.117996\n",
      "85.01%, 0:01:07.187987\n",
      "86.01%, 0:01:07.266803\n",
      "87.00%, 0:01:07.378579\n",
      "88.00%, 0:01:08.433669\n",
      "89.01%, 0:01:09.455134\n",
      "90.01%, 0:01:09.577272\n",
      "91.01%, 0:01:09.853676\n",
      "92.01%, 0:01:11.640391\n",
      "93.00%, 0:01:11.822394\n",
      "94.00%, 0:01:12.505577\n",
      "95.01%, 0:01:13.873464\n",
      "96.01%, 0:01:14.550821\n",
      "97.01%, 0:01:15.018493\n",
      "98.01%, 0:01:16.195957\n",
      "99.00%, 0:01:17.733277\n",
      "100.00%, 0:01:18.815335\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"global\": {},\n",
    "    \"track_id\":{}\n",
    "}\n",
    "for word in global_words:\n",
    "    data[\"global\"][word] = 0\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p = 0\n",
    "\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get word bin counts for each track_id\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "    \n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    # create a dictionary with each unique word as a key with value = 0\n",
    "    data[\"track_id\"][track_id] = {}\n",
    "    for word in unique_words:\n",
    "        data[\"track_id\"][track_id][word] = 0\n",
    "    \n",
    "    # go through the clean playlist words and tabulate using the dictionary\n",
    "    # tally global words as well\n",
    "    for word in playlist_words:\n",
    "        data[\"track_id\"][track_id][word] += 1\n",
    "        data[\"global\"][word] += 1\n",
    "\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02a9668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a single json\n",
    "with open(\"word_count_data.json\",\"w\") as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
