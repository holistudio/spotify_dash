{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846c74de",
   "metadata": {},
   "source": [
    "# Clean Combined Dataset\n",
    "\n",
    "Remove as many \"non-vibe\" words from playlist names and get word occurence counts for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4630009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052a07d",
   "metadata": {},
   "source": [
    "## Load combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deda4eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>playlist_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7k9GuJYLp2AzqokyEdwEw2</td>\n",
       "      <td>Ross Copperman</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>56</td>\n",
       "      <td>205594</td>\n",
       "      <td>False</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>78.899</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>high, high, AUTUMN, Vampire Diaries, sleep, i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1KHdq8NK9QxnGjdXb55NiG</td>\n",
       "      <td>Landon Pigg</td>\n",
       "      <td>The Boy Who Never</td>\n",
       "      <td>Falling in Love at a Coffee Shop</td>\n",
       "      <td>58</td>\n",
       "      <td>244986</td>\n",
       "      <td>False</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.561</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>83.457</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Say You Won't Let Go, mellow, Dance, Chillin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2qLMf6TuEC3ruGJg4SMMN6</td>\n",
       "      <td>Jason Mraz;Colbie Caillat</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>Lucky</td>\n",
       "      <td>68</td>\n",
       "      <td>189613</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>130.088</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3S0OXQeoh0w6AY8WQVckRW</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>75</td>\n",
       "      <td>242946</td>\n",
       "      <td>False</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>150.960</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>tb, Catchy Songs, #boostyourrun, go to, Atlas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5TvE3pk05pyFIGdSY9j4DJ</td>\n",
       "      <td>A Great Big World;Christina Aguilera</td>\n",
       "      <td>Is There Anybody Out There? - Track by Track C...</td>\n",
       "      <td>Say Something</td>\n",
       "      <td>70</td>\n",
       "      <td>229400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>141.284</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>~Rando~, go to, Solitude, Acoustic, happy, yo,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                               artists  \\\n",
       "0  7k9GuJYLp2AzqokyEdwEw2                        Ross Copperman   \n",
       "1  1KHdq8NK9QxnGjdXb55NiG                           Landon Pigg   \n",
       "2  2qLMf6TuEC3ruGJg4SMMN6             Jason Mraz;Colbie Caillat   \n",
       "3  3S0OXQeoh0w6AY8WQVckRW                            Jason Mraz   \n",
       "4  5TvE3pk05pyFIGdSY9j4DJ  A Great Big World;Christina Aguilera   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Hunger   \n",
       "1                                  The Boy Who Never   \n",
       "2                We Sing. We Dance. We Steal Things.   \n",
       "3                We Sing. We Dance. We Steal Things.   \n",
       "4  Is There Anybody Out There? - Track by Track C...   \n",
       "\n",
       "                         track_name popularity duration_ms explicit  \\\n",
       "0                            Hunger         56      205594    False   \n",
       "1  Falling in Love at a Coffee Shop         58      244986    False   \n",
       "2                             Lucky         68      189613    False   \n",
       "3                         I'm Yours         75      242946    False   \n",
       "4                     Say Something         70      229400    False   \n",
       "\n",
       "   danceability  energy key  ...  mode speechiness  acousticness  \\\n",
       "0         0.442   0.632   1  ...     1      0.0295         0.426   \n",
       "1         0.489   0.561   4  ...     1      0.0274         0.200   \n",
       "2         0.625   0.414   0  ...     1      0.0369         0.294   \n",
       "3         0.703   0.444  11  ...     1      0.0417         0.559   \n",
       "4         0.407   0.147   2  ...     1      0.0355         0.857   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \\\n",
       "0          0.004190    0.0735   0.1960   78.899               4    acoustic   \n",
       "1          0.000046    0.1790   0.2380   83.457               3    acoustic   \n",
       "2          0.000000    0.1510   0.6690  130.088               4    acoustic   \n",
       "3          0.000000    0.0973   0.7120  150.960               4    acoustic   \n",
       "4          0.000003    0.0913   0.0765  141.284               3    acoustic   \n",
       "\n",
       "                                      playlist_names  \n",
       "0  high, high, AUTUMN, Vampire Diaries, sleep, i ...  \n",
       "1  Say You Won't Let Go, mellow, Dance, Chillin, ...  \n",
       "2  Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...  \n",
       "3  tb, Catchy Songs, #boostyourrun, go to, Atlas,...  \n",
       "4  ~Rando~, go to, Solitude, Acoustic, happy, yo,...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join('..','..','datasets','tracks_playlist_dataset')\n",
    "\n",
    "df_file_path = os.path.join(dataset_dir,'tracks_playlists_df.pkl')\n",
    "\n",
    "df = pd.read_pickle(df_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48dd5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179120af",
   "metadata": {},
   "source": [
    "## Analyze raw words in playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a8bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c97f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tb',\n",
       " ' Catchy Songs',\n",
       " ' #boostyourrun',\n",
       " ' go to',\n",
       " ' Atlas',\n",
       " ' throwback',\n",
       " ' Acoustic',\n",
       " ' ((chris))',\n",
       " ' throw backs',\n",
       " ' Throwbacks ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68738752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Shower',\n",
       " ' throwback ',\n",
       " ' Stuff I like',\n",
       " ' Classics',\n",
       " ' good times',\n",
       " ' Throwback',\n",
       " ' Songs that never fail to make white people beyond turnt',\n",
       " ' kareoke',\n",
       " ' I love You',\n",
       " ' Lake']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569df4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '5TvE3pk05pyFIGdSY9j4DJ'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e88b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~Rando~',\n",
       " ' go to',\n",
       " ' Solitude',\n",
       " ' Acoustic',\n",
       " ' happy',\n",
       " ' yo',\n",
       " ' my heart',\n",
       " ' Isis',\n",
       " ' Top Hits',\n",
       " ' Mya']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6211d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Depressing songs',\n",
       " ' Easy Listening',\n",
       " ' GRAD',\n",
       " ' L.o.v.e',\n",
       " ' Ballads',\n",
       " ' Inside Out: So Emotional',\n",
       " ' Slow',\n",
       " ' feels',\n",
       " ' Sleep',\n",
       " ' sad times']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2649d01",
   "metadata": {},
   "source": [
    "## Clean playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c2c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles\n",
    "articles = [\n",
    "    \"a\", \"an\", \"the\"\n",
    "]\n",
    "\n",
    "# Common Prepositions\n",
    "# prepositions = [\n",
    "#     \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "#     \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "#     \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "#     \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "#     \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "#     \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"outside\", \"over\", \"past\",\n",
    "#     \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\",\n",
    "#     \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\",\n",
    "#     \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "# ]\n",
    "\n",
    "prepositions = [\n",
    "    \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "    \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "    \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "    \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "    \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "    \"near\", \"of\", \"off\", \"on\", \"onto\", \"outside\", \"over\",\n",
    "    \"per\", \"plus\", \"regarding\", \"round\", \"since\", \"than\", \"through\",\n",
    "    \"to\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "]\n",
    "\n",
    "# Pronouns (personal, possessive, reflexive, demonstrative, relative, interrogative, indefinite)\n",
    "pronouns = [\n",
    "    # Personal\n",
    "    \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\",\n",
    "    # Possessive\n",
    "    \"my\", \"mine\", \"your\", \"yours\", \"his\", \"her\", \"hers\", \"its\", \"our\", \"ours\", \"their\", \"theirs\",\n",
    "    # Reflexive\n",
    "    \"myself\", \"yourself\", \"himself\", \"herself\", \"itself\", \"ourselves\", \"yourselves\", \"themselves\",\n",
    "    # Demonstrative\n",
    "    \"this\", \"that\", \"these\", \"those\",\n",
    "    # Relative\n",
    "    \"who\", \"whom\", \"whose\", \"which\", \"that\",\n",
    "    # Interrogative\n",
    "    \"what\", \"which\", \"who\", \"whom\", \"whose\",\n",
    "    # Indefinite\n",
    "    \"anybody\", \"anyone\", \"anything\", \"each\", \"either\", \"everybody\", \"everyone\", \"everything\",\n",
    "    \"neither\", \"nobody\", \"no one\", \"nothing\", \"one\", \"somebody\", \"someone\", \"something\",\n",
    "    \"both\", \"few\", \"many\", \"several\", \"all\", \"any\", \"most\", \"none\", \"some\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77933892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove synonyms for music/songs\n",
    "# music_stopwords = [\n",
    "#     # General music terms\n",
    "#     \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "#     \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "#     # Album / playlist words\n",
    "#     \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "#     \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "#     # Performance terms\n",
    "#     \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "#     \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "#     # Listening context\n",
    "#     \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "#     \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "#     # Time/context in music\n",
    "#     \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "#     \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "#     # Streaming platform common words\n",
    "#     \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "#     # Music role terms\n",
    "#     \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "#     # Genre meta-words (not actual genres)\n",
    "#     \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "#     \"new\", \"latest\", \"classic\", \"classics\", \"oldies\"\n",
    "# ]\n",
    "\n",
    "music_stopwords = [\n",
    "    # General music terms\n",
    "    \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "    \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "    # Album / playlist words\n",
    "    \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "    \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "    # Performance terms\n",
    "    \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "    \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "    # Listening context\n",
    "    \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "    \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "    # Time/context in music\n",
    "    \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "    \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "    # Streaming platform common words\n",
    "    \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "    # Music role terms\n",
    "    \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "    # Genre meta-words (not actual genres)\n",
    "    \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "    \"new\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d1c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude feels words\n",
    "\n",
    "# emotion_words = [\n",
    "#     # Feelings (general emotional states)\n",
    "#     \"emotions\", \"sentiments\", \"sensations\", \"reactions\", \"responses\",\n",
    "#     \"passions\", \"affection\", \"affects\", \"attitudes\", \"vibes\",\n",
    "    \n",
    "#     # Mood (emotional tone)\n",
    "#     \"temper\", \"disposition\", \"frame_of_mind\", \"outlook\", \"mindset\",\n",
    "#     \"spirit\", \"tone\", \"ambience\", \"atmosphere\", \"energy\",\n",
    "    \n",
    "#     # Colloquial / modern terms\n",
    "#     \"vibes\", \"aura\", \"feels\", \"headspace\", \"energy\",\n",
    "    \n",
    "#     # More poetic/formal variants\n",
    "#     \"humor\", \"mien\", \"temperament\", \"sentiment\", \"state_of_mind\",\n",
    "#     \"air\", \"bearing\", \"character\"\n",
    "# ]\n",
    "\n",
    "emotion_words = [\n",
    "    \"emotions\", \"emotion\",\n",
    "    \"feelings\", \"feeling\",\n",
    "    \"attitude\", \"attitudes\", \n",
    "    \"vibe\", \"vibes\", \n",
    "    \"feel\", \"feels\", \"headspace\",\n",
    "    \"character\", \"mood\", \"moody\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58362fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_playlist_names(track_id):\n",
    "    # find track_id in DataFrame\n",
    "    filter = df['track_id'] == track_id\n",
    "    row = df[filter].iloc[0]\n",
    "\n",
    "    # get playlist names \n",
    "    playlist_names = row['playlist_names']\n",
    "\n",
    "    # convert to a list\n",
    "    playlist_names = playlist_names.split(',')\n",
    "\n",
    "    # separate into distinct words\n",
    "    playlist_words = []\n",
    "    for name in playlist_names:\n",
    "        # convert to lower case\n",
    "        n = name.lower()\n",
    "\n",
    "        # remove symbols and emojis\n",
    "        n = re.sub(r\"[^\\w\\s]\", \"\", n, flags=re.UNICODE)\n",
    "\n",
    "        # remove all numbers\n",
    "        n = re.sub(r'\\d+', '', n)  # Remove all digits\n",
    "\n",
    "        # remove '_' character\n",
    "        n = n.replace(\"_\", \"\")\n",
    "        \n",
    "        # split based on spaces\n",
    "        n = n.split(' ')\n",
    "        \n",
    "        for word in n:\n",
    "            # exclude articles, prepositions, pronouns\n",
    "            exc0 = len(word) <= 1\n",
    "            exc1 = word in articles\n",
    "            exc2 = word in prepositions\n",
    "            exc3 = word in pronouns\n",
    "\n",
    "            # exclude music stop words\n",
    "            exc4 = word in music_stopwords\n",
    "\n",
    "            # exclude emotion words\n",
    "            exc5 = word in emotion_words\n",
    "\n",
    "            word_ok = not (exc0 or exc1 or exc2 or exc3 or exc4 or\n",
    "                           exc5)\n",
    "            \n",
    "            if word_ok:\n",
    "                playlist_words.append(word)\n",
    "\n",
    "    return playlist_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423ea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id=track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc9aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'go',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'yo',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a6201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'ds',\n",
       " 'let',\n",
       " 'go',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'so',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3410580",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id='5TvE3pk05pyFIGdSY9j4DJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e0fcc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'go',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'yo',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff4372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'ds',\n",
       " 'let',\n",
       " 'go',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'so',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a075352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10444"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(playlist_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "102c5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2102"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(playlist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c78475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove 's' from plural forms of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0354f9",
   "metadata": {},
   "source": [
    "## Get word bin counts for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0704aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each track_id\n",
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "\n",
    "# get clean playlist words\n",
    "playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "# get unique playlist words\n",
    "unique_words = set(playlist_words)\n",
    "\n",
    "# create a dictionary with each unique word as a key with value = 0\n",
    "word_bins = {}\n",
    "for word in unique_words:\n",
    "    word_bins[word] = 0\n",
    "\n",
    "# go through the clean playlist words and tabulate using the dictionary\n",
    "for word in playlist_words:\n",
    "    word_bins[word] += 1\n",
    "\n",
    "# convert into a list of words sorted by bin count\n",
    "sorted_items = sorted(word_bins.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d843b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chill', 881),\n",
       " ('wedding', 682),\n",
       " ('love', 659),\n",
       " ('throwback', 656),\n",
       " ('good', 577),\n",
       " ('throwbacks', 341),\n",
       " ('happy', 327),\n",
       " ('summer', 285),\n",
       " ('pop', 266),\n",
       " ('car', 250),\n",
       " ('party', 246),\n",
       " ('beach', 207),\n",
       " ('old', 201),\n",
       " ('road', 188),\n",
       " ('oldies', 165),\n",
       " ('sing', 152),\n",
       " ('dinner', 146),\n",
       " ('trip', 145),\n",
       " ('shower', 145),\n",
       " ('mellow', 140)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "815d2f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('hiking', 1),\n",
       " ('guard', 1),\n",
       " ('isabella', 1),\n",
       " ('annas', 1),\n",
       " ('brain', 1),\n",
       " ('british', 1),\n",
       " ('machine', 1),\n",
       " ('flora', 1),\n",
       " ('robert', 1),\n",
       " ('demons', 1),\n",
       " ('native', 1),\n",
       " ('mystic', 1),\n",
       " ('garrett', 1),\n",
       " ('billboard', 1),\n",
       " ('uh', 1),\n",
       " ('beatriz', 1),\n",
       " ('contry', 1),\n",
       " ('pumpkin', 1),\n",
       " ('mice', 1),\n",
       " ('breath', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b03ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2666"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fad2b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.013000\n",
      "1.01%, 0:00:02.246733\n",
      "2.01%, 0:00:02.917110\n",
      "3.01%, 0:00:03.317543\n",
      "4.01%, 0:00:07.852257\n",
      "5.00%, 0:00:11.423606\n",
      "6.02%, 0:00:14.588035\n",
      "7.01%, 0:00:16.362815\n",
      "8.01%, 0:00:16.831348\n",
      "9.01%, 0:00:17.112353\n",
      "10.00%, 0:00:17.233705\n",
      "11.00%, 0:00:17.416267\n",
      "12.02%, 0:00:17.629667\n",
      "13.01%, 0:00:17.767971\n",
      "14.01%, 0:00:19.196945\n",
      "15.01%, 0:00:22.334762\n",
      "16.00%, 0:00:23.770836\n",
      "17.00%, 0:00:24.439082\n",
      "18.02%, 0:00:24.606354\n",
      "19.01%, 0:00:26.006368\n",
      "20.01%, 0:00:27.006629\n",
      "21.01%, 0:00:27.579693\n",
      "22.00%, 0:00:27.839629\n",
      "23.00%, 0:00:27.944414\n",
      "24.02%, 0:00:28.045510\n",
      "25.01%, 0:00:28.890524\n",
      "26.01%, 0:00:29.090356\n",
      "27.01%, 0:00:29.246164\n",
      "28.00%, 0:00:29.636769\n",
      "29.00%, 0:00:32.740201\n",
      "30.01%, 0:00:39.602707\n",
      "31.01%, 0:00:45.308816\n",
      "32.01%, 0:00:45.693456\n",
      "33.01%, 0:00:45.823037\n",
      "34.00%, 0:00:46.227992\n",
      "35.00%, 0:00:46.675416\n",
      "36.01%, 0:00:48.327212\n",
      "37.01%, 0:00:49.346959\n",
      "38.01%, 0:00:50.645086\n",
      "39.01%, 0:00:50.917998\n",
      "40.00%, 0:00:51.249263\n",
      "41.00%, 0:00:51.712976\n",
      "42.01%, 0:00:55.669815\n",
      "43.01%, 0:01:00.490730\n",
      "44.01%, 0:01:01.709312\n",
      "45.01%, 0:01:04.846921\n",
      "46.00%, 0:01:06.088273\n",
      "47.00%, 0:01:09.697965\n",
      "48.01%, 0:01:11.954240\n",
      "49.01%, 0:01:12.727301\n",
      "50.01%, 0:01:13.283727\n",
      "51.01%, 0:01:13.753038\n",
      "52.00%, 0:01:13.905157\n",
      "53.02%, 0:01:14.278570\n",
      "54.01%, 0:01:16.591410\n",
      "55.01%, 0:01:18.608276\n",
      "56.01%, 0:01:19.894195\n",
      "57.01%, 0:01:20.529282\n",
      "58.00%, 0:01:21.210653\n",
      "59.02%, 0:01:21.502443\n",
      "60.01%, 0:01:21.597732\n",
      "61.01%, 0:01:26.433733\n",
      "62.01%, 0:01:28.938745\n",
      "63.00%, 0:01:30.436546\n",
      "64.00%, 0:01:33.633753\n",
      "65.02%, 0:01:34.375076\n",
      "66.01%, 0:01:34.707312\n",
      "67.01%, 0:01:37.945254\n",
      "68.01%, 0:01:38.580379\n",
      "69.00%, 0:01:38.707365\n",
      "70.00%, 0:01:41.450617\n",
      "71.02%, 0:01:41.683300\n",
      "72.01%, 0:01:44.147516\n",
      "73.01%, 0:01:44.954318\n",
      "74.01%, 0:01:45.354933\n",
      "75.00%, 0:01:46.971617\n",
      "76.00%, 0:01:47.219175\n",
      "77.02%, 0:01:47.354442\n",
      "78.01%, 0:01:47.467369\n",
      "79.01%, 0:01:48.455825\n",
      "80.01%, 0:01:49.748435\n",
      "81.00%, 0:01:50.309959\n",
      "82.00%, 0:01:50.559465\n",
      "83.01%, 0:01:50.693945\n",
      "84.01%, 0:01:50.818784\n",
      "85.01%, 0:01:50.927198\n",
      "86.01%, 0:01:51.023325\n",
      "87.00%, 0:01:51.191312\n",
      "88.00%, 0:01:52.894617\n",
      "89.01%, 0:01:54.461966\n",
      "90.01%, 0:01:54.664533\n",
      "91.01%, 0:01:55.096164\n",
      "92.01%, 0:01:57.948127\n",
      "93.00%, 0:01:58.216549\n",
      "94.00%, 0:01:59.617204\n",
      "95.01%, 0:02:02.039832\n",
      "96.01%, 0:02:03.104681\n",
      "97.01%, 0:02:04.142630\n",
      "98.01%, 0:02:05.924782\n",
      "99.00%, 0:02:08.226626\n",
      "100.00%, 0:02:09.894460\n"
     ]
    }
   ],
   "source": [
    "# Figure out how many unique words are there in all playlists for all tracks\n",
    "global_words = []\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p=0\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    for w in unique_words:\n",
    "        if w not in global_words:\n",
    "            global_words.append(w)\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c374e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9723"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f0250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f3ca3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.015910\n",
      "1.01%, 0:00:01.476617\n",
      "2.01%, 0:00:01.877379\n",
      "3.01%, 0:00:02.118952\n",
      "4.01%, 0:00:04.914080\n",
      "5.00%, 0:00:07.219510\n",
      "6.02%, 0:00:09.034866\n",
      "7.01%, 0:00:09.985443\n",
      "8.01%, 0:00:10.236704\n",
      "9.01%, 0:00:10.403715\n",
      "10.00%, 0:00:10.485625\n",
      "11.00%, 0:00:10.589262\n",
      "12.02%, 0:00:10.722454\n",
      "13.01%, 0:00:10.798887\n",
      "14.01%, 0:00:11.708025\n",
      "15.01%, 0:00:13.622438\n",
      "16.00%, 0:00:14.440988\n",
      "17.00%, 0:00:14.798887\n",
      "18.02%, 0:00:14.889885\n",
      "19.01%, 0:00:15.724543\n",
      "20.01%, 0:00:16.257983\n",
      "21.01%, 0:00:16.547114\n",
      "22.00%, 0:00:16.691810\n",
      "23.00%, 0:00:16.746438\n",
      "24.02%, 0:00:16.810184\n",
      "25.01%, 0:00:17.259328\n",
      "26.01%, 0:00:17.359446\n",
      "27.01%, 0:00:17.476785\n",
      "28.00%, 0:00:17.697829\n",
      "29.00%, 0:00:19.782915\n",
      "30.01%, 0:00:24.232955\n",
      "31.01%, 0:00:27.839646\n",
      "32.01%, 0:00:28.041192\n",
      "33.01%, 0:00:28.103587\n",
      "34.00%, 0:00:28.354712\n",
      "35.00%, 0:00:28.573689\n",
      "36.01%, 0:00:29.605037\n",
      "37.01%, 0:00:30.157107\n",
      "38.01%, 0:00:31.073474\n",
      "39.01%, 0:00:31.261362\n",
      "40.00%, 0:00:31.415240\n",
      "41.00%, 0:00:31.658611\n",
      "42.01%, 0:00:33.981577\n",
      "43.01%, 0:00:36.686689\n",
      "44.01%, 0:00:37.279876\n",
      "45.01%, 0:00:39.081413\n",
      "46.00%, 0:00:39.815457\n",
      "47.00%, 0:00:42.118075\n",
      "48.01%, 0:00:43.455917\n",
      "49.01%, 0:00:43.838253\n",
      "50.01%, 0:00:44.139525\n",
      "51.01%, 0:00:44.387095\n",
      "52.00%, 0:00:44.471224\n",
      "53.02%, 0:00:44.673361\n",
      "54.01%, 0:00:45.955535\n",
      "55.01%, 0:00:47.122946\n",
      "56.01%, 0:00:47.824969\n",
      "57.01%, 0:00:48.205052\n",
      "58.00%, 0:00:48.587387\n",
      "59.02%, 0:00:48.724506\n",
      "60.01%, 0:00:48.791628\n",
      "61.01%, 0:00:52.082720\n",
      "62.01%, 0:00:53.684634\n",
      "63.00%, 0:00:54.615345\n",
      "64.00%, 0:00:56.469335\n",
      "65.02%, 0:00:56.885959\n",
      "66.01%, 0:00:57.051132\n",
      "67.01%, 0:00:59.320237\n",
      "68.01%, 0:00:59.753960\n",
      "69.00%, 0:00:59.837841\n",
      "70.00%, 0:01:01.422369\n",
      "71.02%, 0:01:01.555775\n",
      "72.01%, 0:01:03.127336\n",
      "73.01%, 0:01:03.624738\n",
      "74.01%, 0:01:03.861611\n",
      "75.00%, 0:01:04.792382\n",
      "76.00%, 0:01:04.926029\n",
      "77.02%, 0:01:04.992653\n",
      "78.01%, 0:01:05.069442\n",
      "79.01%, 0:01:05.611910\n",
      "80.01%, 0:01:06.342619\n",
      "81.00%, 0:01:06.597717\n",
      "82.00%, 0:01:06.743245\n",
      "83.01%, 0:01:06.812999\n",
      "84.01%, 0:01:06.903947\n",
      "85.01%, 0:01:06.976431\n",
      "86.01%, 0:01:07.028028\n",
      "87.00%, 0:01:07.143293\n",
      "88.00%, 0:01:08.162485\n",
      "89.01%, 0:01:09.179045\n",
      "90.01%, 0:01:09.315611\n",
      "91.01%, 0:01:09.600325\n",
      "92.01%, 0:01:11.351734\n",
      "93.00%, 0:01:11.499317\n",
      "94.00%, 0:01:12.200493\n",
      "95.01%, 0:01:13.554156\n",
      "96.01%, 0:01:14.168789\n",
      "97.01%, 0:01:14.554216\n",
      "98.01%, 0:01:15.552017\n",
      "99.00%, 0:01:16.920421\n",
      "100.00%, 0:01:17.905896\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"global\": {},\n",
    "    \"track_id\":{}\n",
    "}\n",
    "for word in global_words:\n",
    "    data[\"global\"][word] = 0\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p = 0\n",
    "\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get word bin counts for each track_id\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "    \n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    # create a dictionary with each unique word as a key with value = 0\n",
    "    data[\"track_id\"][track_id] = {}\n",
    "    for word in unique_words:\n",
    "        data[\"track_id\"][track_id][word] = 0\n",
    "    \n",
    "    # go through the clean playlist words and tabulate using the dictionary\n",
    "    # tally global words as well\n",
    "    for word in playlist_words:\n",
    "        data[\"track_id\"][track_id][word] += 1\n",
    "        data[\"global\"][word] += 1\n",
    "\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02a9668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a single json\n",
    "with open(\"word_count_data.json\",\"w\") as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
