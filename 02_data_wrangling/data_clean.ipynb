{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "846c74de",
   "metadata": {},
   "source": [
    "# Clean Combined Dataset\n",
    "\n",
    "Remove as many \"non-vibe\" words from playlist names and get word occurence counts for each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4630009f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import datetime\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7052a07d",
   "metadata": {},
   "source": [
    "## Load combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "deda4eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>artists</th>\n",
       "      <th>album_name</th>\n",
       "      <th>track_name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>explicit</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>...</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>valence</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>track_genre</th>\n",
       "      <th>playlist_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7k9GuJYLp2AzqokyEdwEw2</td>\n",
       "      <td>Ross Copperman</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>Hunger</td>\n",
       "      <td>56</td>\n",
       "      <td>205594</td>\n",
       "      <td>False</td>\n",
       "      <td>0.442</td>\n",
       "      <td>0.632</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>0.0735</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>78.899</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>high, high, AUTUMN, Vampire Diaries, sleep, i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1KHdq8NK9QxnGjdXb55NiG</td>\n",
       "      <td>Landon Pigg</td>\n",
       "      <td>The Boy Who Never</td>\n",
       "      <td>Falling in Love at a Coffee Shop</td>\n",
       "      <td>58</td>\n",
       "      <td>244986</td>\n",
       "      <td>False</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.561</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.000046</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.2380</td>\n",
       "      <td>83.457</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Say You Won't Let Go, mellow, Dance, Chillin, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2qLMf6TuEC3ruGJg4SMMN6</td>\n",
       "      <td>Jason Mraz;Colbie Caillat</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>Lucky</td>\n",
       "      <td>68</td>\n",
       "      <td>189613</td>\n",
       "      <td>False</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.414</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>0.6690</td>\n",
       "      <td>130.088</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3S0OXQeoh0w6AY8WQVckRW</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>We Sing. We Dance. We Steal Things.</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>75</td>\n",
       "      <td>242946</td>\n",
       "      <td>False</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>150.960</td>\n",
       "      <td>4</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>tb, Catchy Songs, #boostyourrun, go to, Atlas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5TvE3pk05pyFIGdSY9j4DJ</td>\n",
       "      <td>A Great Big World;Christina Aguilera</td>\n",
       "      <td>Is There Anybody Out There? - Track by Track C...</td>\n",
       "      <td>Say Something</td>\n",
       "      <td>70</td>\n",
       "      <td>229400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.147</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>141.284</td>\n",
       "      <td>3</td>\n",
       "      <td>acoustic</td>\n",
       "      <td>~Rando~, go to, Solitude, Acoustic, happy, yo,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 track_id                               artists  \\\n",
       "0  7k9GuJYLp2AzqokyEdwEw2                        Ross Copperman   \n",
       "1  1KHdq8NK9QxnGjdXb55NiG                           Landon Pigg   \n",
       "2  2qLMf6TuEC3ruGJg4SMMN6             Jason Mraz;Colbie Caillat   \n",
       "3  3S0OXQeoh0w6AY8WQVckRW                            Jason Mraz   \n",
       "4  5TvE3pk05pyFIGdSY9j4DJ  A Great Big World;Christina Aguilera   \n",
       "\n",
       "                                          album_name  \\\n",
       "0                                             Hunger   \n",
       "1                                  The Boy Who Never   \n",
       "2                We Sing. We Dance. We Steal Things.   \n",
       "3                We Sing. We Dance. We Steal Things.   \n",
       "4  Is There Anybody Out There? - Track by Track C...   \n",
       "\n",
       "                         track_name popularity duration_ms explicit  \\\n",
       "0                            Hunger         56      205594    False   \n",
       "1  Falling in Love at a Coffee Shop         58      244986    False   \n",
       "2                             Lucky         68      189613    False   \n",
       "3                         I'm Yours         75      242946    False   \n",
       "4                     Say Something         70      229400    False   \n",
       "\n",
       "   danceability  energy key  ...  mode speechiness  acousticness  \\\n",
       "0         0.442   0.632   1  ...     1      0.0295         0.426   \n",
       "1         0.489   0.561   4  ...     1      0.0274         0.200   \n",
       "2         0.625   0.414   0  ...     1      0.0369         0.294   \n",
       "3         0.703   0.444  11  ...     1      0.0417         0.559   \n",
       "4         0.407   0.147   2  ...     1      0.0355         0.857   \n",
       "\n",
       "   instrumentalness  liveness  valence    tempo  time_signature track_genre  \\\n",
       "0          0.004190    0.0735   0.1960   78.899               4    acoustic   \n",
       "1          0.000046    0.1790   0.2380   83.457               3    acoustic   \n",
       "2          0.000000    0.1510   0.6690  130.088               4    acoustic   \n",
       "3          0.000000    0.0973   0.7120  150.960               4    acoustic   \n",
       "4          0.000003    0.0913   0.0765  141.284               3    acoustic   \n",
       "\n",
       "                                      playlist_names  \n",
       "0  high, high, AUTUMN, Vampire Diaries, sleep, i ...  \n",
       "1  Say You Won't Let Go, mellow, Dance, Chillin, ...  \n",
       "2  Wedding, #boostyourrun, go to, Acoustic, üòçüòçüòç, ...  \n",
       "3  tb, Catchy Songs, #boostyourrun, go to, Atlas,...  \n",
       "4  ~Rando~, go to, Solitude, Acoustic, happy, yo,...  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir = os.path.join('..','..','datasets','tracks_playlist_dataset')\n",
    "\n",
    "df_file_path = os.path.join(dataset_dir,'tracks_playlists_df.pkl')\n",
    "\n",
    "df = pd.read_pickle(df_file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e48dd5a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7560"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179120af",
   "metadata": {},
   "source": [
    "## Analyze raw words in playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96a8bca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c97f183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tb',\n",
       " ' Catchy Songs',\n",
       " ' #boostyourrun',\n",
       " ' go to',\n",
       " ' Atlas',\n",
       " ' throwback',\n",
       " ' Acoustic',\n",
       " ' ((chris))',\n",
       " ' throw backs',\n",
       " ' Throwbacks ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68738752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Shower',\n",
       " ' throwback ',\n",
       " ' Stuff I like',\n",
       " ' Classics',\n",
       " ' good times',\n",
       " ' Throwback',\n",
       " ' Songs that never fail to make white people beyond turnt',\n",
       " ' kareoke',\n",
       " ' I love You',\n",
       " ' Lake']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "569df4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_id = '5TvE3pk05pyFIGdSY9j4DJ'\n",
    "filter = df['track_id'] == track_id\n",
    "row = df[filter].iloc[0]\n",
    "playlist_names = row['playlist_names']\n",
    "playlist_names = playlist_names.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41e88b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['~Rando~',\n",
       " ' go to',\n",
       " ' Solitude',\n",
       " ' Acoustic',\n",
       " ' happy',\n",
       " ' yo',\n",
       " ' my heart',\n",
       " ' Isis',\n",
       " ' Top Hits',\n",
       " ' Mya']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6211d4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Depressing songs',\n",
       " ' Easy Listening',\n",
       " ' GRAD',\n",
       " ' L.o.v.e',\n",
       " ' Ballads',\n",
       " ' Inside Out: So Emotional',\n",
       " ' Slow',\n",
       " ' feels',\n",
       " ' Sleep',\n",
       " ' sad times']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_names[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2649d01",
   "metadata": {},
   "source": [
    "## Clean playlist names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51c2c72f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles\n",
    "articles = [\n",
    "    \"a\", \"an\", \"the\"\n",
    "]\n",
    "\n",
    "# Common Prepositions\n",
    "# prepositions = [\n",
    "#     \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "#     \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "#     \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "#     \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "#     \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "#     \"near\", \"of\", \"off\", \"on\", \"onto\", \"opposite\", \"outside\", \"over\", \"past\",\n",
    "#     \"per\", \"plus\", \"regarding\", \"round\", \"save\", \"since\", \"than\", \"through\",\n",
    "#     \"to\", \"toward\", \"towards\", \"under\", \"underneath\", \"unlike\", \"until\",\n",
    "#     \"up\", \"upon\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "# ]\n",
    "\n",
    "prepositions = [\n",
    "    \"about\", \"above\", \"across\", \"after\", \"against\", \"along\", \"among\",\n",
    "    \"around\", \"at\", \"before\", \"behind\", \"below\", \"beneath\", \"beside\",\n",
    "    \"besides\", \"between\", \"beyond\", \"but\", \"by\", \"concerning\", \"considering\",\n",
    "    \"despite\", \"down\", \"during\", \"except\", \"excepting\", \"excluding\",\n",
    "    \"following\", \"for\", \"from\", \"in\", \"inside\", \"into\", \"like\", \"minus\",\n",
    "    \"near\", \"of\", \"off\", \"on\", \"onto\", \"outside\", \"over\",\n",
    "    \"per\", \"plus\", \"regarding\", \"round\", \"since\", \"than\", \"through\",\n",
    "    \"to\", \"versus\", \"via\", \"with\", \"within\", \"without\"\n",
    "]\n",
    "\n",
    "# Pronouns (personal, possessive, reflexive, demonstrative, relative, interrogative, indefinite)\n",
    "pronouns = [\n",
    "    # Personal\n",
    "    \"i\", \"you\", \"he\", \"she\", \"it\", \"we\", \"they\", \"me\", \"him\", \"her\", \"us\", \"them\",\n",
    "    # Possessive\n",
    "    \"my\", \"mine\", \"your\", \"yours\", \"his\", \"her\", \"hers\", \"its\", \"our\", \"ours\", \"their\", \"theirs\",\n",
    "    # Reflexive\n",
    "    \"myself\", \"yourself\", \"himself\", \"herself\", \"itself\", \"ourselves\", \"yourselves\", \"themselves\",\n",
    "    # Demonstrative\n",
    "    \"this\", \"that\", \"these\", \"those\",\n",
    "    # Relative\n",
    "    \"who\", \"whom\", \"whose\", \"which\", \"that\",\n",
    "    # Interrogative\n",
    "    \"what\", \"which\", \"who\", \"whom\", \"whose\",\n",
    "    # Indefinite\n",
    "    \"anybody\", \"anyone\", \"anything\", \"each\", \"either\", \"everybody\", \"everyone\", \"everything\",\n",
    "    \"neither\", \"nobody\", \"no one\", \"nothing\", \"one\", \"somebody\", \"someone\", \"something\",\n",
    "    \"both\", \"few\", \"many\", \"several\", \"all\", \"any\", \"most\", \"none\", \"some\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77933892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove synonyms for music/songs\n",
    "# music_stopwords = [\n",
    "#     # General music terms\n",
    "#     \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "#     \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "#     # Album / playlist words\n",
    "#     \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "#     \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "#     # Performance terms\n",
    "#     \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "#     \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "#     # Listening context\n",
    "#     \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "#     \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "#     # Time/context in music\n",
    "#     \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "#     \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "#     # Streaming platform common words\n",
    "#     \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "#     # Music role terms\n",
    "#     \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "#     # Genre meta-words (not actual genres)\n",
    "#     \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "#     \"new\", \"latest\", \"classic\", \"classics\", \"oldies\"\n",
    "# ]\n",
    "\n",
    "music_stopwords = [\n",
    "    # General music terms\n",
    "    \"music\", \"song\", \"songs\", \"track\", \"tracks\", \"tune\", \"tunes\",\n",
    "    \"melody\", \"melodies\", \"rhythm\", \"harmony\", \"lyrics\",\n",
    "    \n",
    "    # Album / playlist words\n",
    "    \"playlist\", \"mix\", \"compilation\", \"collection\", \"set\", \"jam\", \"jams\",\n",
    "    \"record\", \"records\", \"album\", \"albums\", \"single\", \"singles\", \"ep\", \"lp\",\n",
    "    \n",
    "    # Performance terms\n",
    "    \"band\", \"bands\", \"group\", \"groups\", \"orchestra\", \"choir\", \"ensemble\",\n",
    "    \"performance\", \"performances\", \"concert\", \"gig\", \"show\", \"live\",\n",
    "    \n",
    "    # Listening context\n",
    "    \"listen\", \"listening\", \"play\", \"played\", \"plays\", \"playing\",\n",
    "    \"sound\", \"sounds\", \"audio\",\n",
    "    \n",
    "    # Time/context in music\n",
    "    \"remix\", \"remixes\", \"cover\", \"covers\", \"version\", \"versions\",\n",
    "    \"original\", \"edit\", \"edits\", \"demo\", \"demos\",\n",
    "    \n",
    "    # Streaming platform common words\n",
    "    \"radio\", \"station\", \"stations\", \"session\", \"sessions\",\n",
    "    \n",
    "    # Music role terms\n",
    "    \"dj\", \"producer\", \"production\", \"artist\", \"artists\", \"musician\", \"musicians\",\n",
    "    \n",
    "    # Genre meta-words (not actual genres)\n",
    "    \"hit\", \"hits\", \"chart\", \"charts\", \"top\", \"best\", \"greatest\", \"favorites\", \"favourite\",\n",
    "    \"new\",\n",
    "\n",
    "    \"spotify\", \"spotifys\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38d1c037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude feels words\n",
    "\n",
    "# emotion_words = [\n",
    "#     # Feelings (general emotional states)\n",
    "#     \"emotions\", \"sentiments\", \"sensations\", \"reactions\", \"responses\",\n",
    "#     \"passions\", \"affection\", \"affects\", \"attitudes\", \"vibes\",\n",
    "    \n",
    "#     # Mood (emotional tone)\n",
    "#     \"temper\", \"disposition\", \"frame_of_mind\", \"outlook\", \"mindset\",\n",
    "#     \"spirit\", \"tone\", \"ambience\", \"atmosphere\", \"energy\",\n",
    "    \n",
    "#     # Colloquial / modern terms\n",
    "#     \"vibes\", \"aura\", \"feels\", \"headspace\", \"energy\",\n",
    "    \n",
    "#     # More poetic/formal variants\n",
    "#     \"humor\", \"mien\", \"temperament\", \"sentiment\", \"state_of_mind\",\n",
    "#     \"air\", \"bearing\", \"character\"\n",
    "# ]\n",
    "\n",
    "emotion_words = [\n",
    "    \"emotions\", \"emotion\",\n",
    "    \"feelings\", \"feeling\",\n",
    "    \"attitude\", \"attitudes\", \n",
    "    \"vibe\", \"vibes\", \n",
    "    \"feel\", \"feels\", \"headspace\",\n",
    "    \"character\", \"mood\", \"moody\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58362fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_playlist_names(track_id):\n",
    "    # find track_id in DataFrame\n",
    "    filter = df['track_id'] == track_id\n",
    "    row = df[filter].iloc[0]\n",
    "\n",
    "    # get playlist names \n",
    "    playlist_names = row['playlist_names']\n",
    "\n",
    "    # convert to a list\n",
    "    playlist_names = playlist_names.split(',')\n",
    "\n",
    "    # separate into distinct words\n",
    "    playlist_words = []\n",
    "    for name in playlist_names:\n",
    "        # convert to lower case\n",
    "        n = name.lower()\n",
    "\n",
    "        # remove symbols and emojis\n",
    "        n = re.sub(r\"[^\\w\\s]\", \"\", n, flags=re.UNICODE)\n",
    "\n",
    "        # remove all numbers\n",
    "        n = re.sub(r'\\d+', '', n)  # Remove all digits\n",
    "\n",
    "        # remove '_' character\n",
    "        n = n.replace(\"_\", \"\")\n",
    "        \n",
    "        # split based on spaces\n",
    "        n = n.split(' ')\n",
    "        \n",
    "        for word in n:\n",
    "            # exclude articles, prepositions, pronouns\n",
    "            exc0 = len(word) <= 2\n",
    "            exc1 = word in articles\n",
    "            exc2 = word in prepositions\n",
    "            exc3 = word in pronouns\n",
    "\n",
    "            # exclude music stop words\n",
    "            exc4 = word in music_stopwords\n",
    "\n",
    "            # exclude emotion words\n",
    "            exc5 = word in emotion_words\n",
    "\n",
    "            word_ok = not (exc0 or exc1 or exc2 or exc3 or exc4 or\n",
    "                           exc5 or word=='stuff')\n",
    "            \n",
    "            if word_ok:\n",
    "                playlist_words.append(word)\n",
    "\n",
    "    return playlist_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "423ea0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id=track_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bc9aa7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure',\n",
       " 'love',\n",
       " 'chill']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37a6201e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential',\n",
       " 'hmmmm',\n",
       " 'alternative',\n",
       " 'jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'let',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3410580",
   "metadata": {},
   "outputs": [],
   "source": [
    "playlist_words = clean_playlist_names(track_id='5TvE3pk05pyFIGdSY9j4DJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e0fcc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rando',\n",
       " 'solitude',\n",
       " 'acoustic',\n",
       " 'happy',\n",
       " 'heart',\n",
       " 'isis',\n",
       " 'mya',\n",
       " 'hayley',\n",
       " 'chill',\n",
       " 'chilly',\n",
       " 'other',\n",
       " 'breathe',\n",
       " 'jens',\n",
       " 'fallen',\n",
       " 'run',\n",
       " 'sad',\n",
       " 'quiet',\n",
       " 'pure',\n",
       " 'love',\n",
       " 'chill']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff4372d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['potential',\n",
       " 'hmmmm',\n",
       " 'alternative',\n",
       " 'jared',\n",
       " 'cry',\n",
       " 'love',\n",
       " 'together',\n",
       " 'confidence',\n",
       " 'let',\n",
       " 'depressing',\n",
       " 'easy',\n",
       " 'grad',\n",
       " 'love',\n",
       " 'ballads',\n",
       " 'out',\n",
       " 'emotional',\n",
       " 'slow',\n",
       " 'sleep',\n",
       " 'sad',\n",
       " 'times']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "playlist_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a075352b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10014"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(playlist_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "102c5ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1983"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(playlist_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "51c78475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: remove 's' from plural forms of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0354f9",
   "metadata": {},
   "source": [
    "## Get word bin counts for each track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0704aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each track_id\n",
    "track_id = '3S0OXQeoh0w6AY8WQVckRW'\n",
    "\n",
    "# get clean playlist words\n",
    "playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "# get unique playlist words\n",
    "unique_words = set(playlist_words)\n",
    "\n",
    "# create a dictionary with each unique word as a key with value = 0\n",
    "word_bins = {}\n",
    "for word in unique_words:\n",
    "    word_bins[word] = 0\n",
    "\n",
    "# go through the clean playlist words and tabulate using the dictionary\n",
    "for word in playlist_words:\n",
    "    word_bins[word] += 1\n",
    "\n",
    "# convert into a list of words sorted by bin count\n",
    "sorted_items = sorted(word_bins.items(), key=lambda x: x[1], reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d843b2d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chill', 881),\n",
       " ('wedding', 682),\n",
       " ('love', 659),\n",
       " ('throwback', 656),\n",
       " ('good', 577),\n",
       " ('throwbacks', 341),\n",
       " ('happy', 327),\n",
       " ('summer', 285),\n",
       " ('pop', 266),\n",
       " ('car', 250),\n",
       " ('party', 246),\n",
       " ('beach', 207),\n",
       " ('old', 201),\n",
       " ('road', 188),\n",
       " ('oldies', 165),\n",
       " ('sing', 152),\n",
       " ('dinner', 146),\n",
       " ('shower', 145),\n",
       " ('trip', 145),\n",
       " ('mellow', 140)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "815d2f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aubrey', 1),\n",
       " ('weekly', 1),\n",
       " ('pbj', 1),\n",
       " ('varias', 1),\n",
       " ('evelyn', 1),\n",
       " ('lame', 1),\n",
       " ('surfs', 1),\n",
       " ('generic', 1),\n",
       " ('war', 1),\n",
       " ('benji', 1),\n",
       " ('kaylee', 1),\n",
       " ('trail', 1),\n",
       " ('rns', 1),\n",
       " ('restore', 1),\n",
       " ('gabs', 1),\n",
       " ('becca', 1),\n",
       " ('vanilla', 1),\n",
       " ('build', 1),\n",
       " ('begin', 1),\n",
       " ('felicia', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b03ac4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2509"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sorted_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fad2b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.014224\n",
      "1.01%, 0:00:02.390143\n",
      "2.01%, 0:00:03.067222\n",
      "3.01%, 0:00:03.483374\n",
      "4.01%, 0:00:08.040575\n",
      "5.00%, 0:00:11.589697\n",
      "6.02%, 0:00:14.611891\n",
      "7.01%, 0:00:16.312442\n",
      "8.01%, 0:00:16.785237\n",
      "9.01%, 0:00:17.050192\n",
      "10.00%, 0:00:17.183603\n",
      "11.00%, 0:00:17.339756\n",
      "12.02%, 0:00:17.539915\n",
      "13.01%, 0:00:17.670022\n",
      "14.01%, 0:00:19.065271\n",
      "15.01%, 0:00:22.134984\n",
      "16.00%, 0:00:23.499809\n",
      "17.00%, 0:00:24.089788\n",
      "18.02%, 0:00:24.271223\n",
      "19.01%, 0:00:25.629891\n",
      "20.01%, 0:00:26.591563\n",
      "21.01%, 0:00:27.079883\n",
      "22.00%, 0:00:27.331002\n",
      "23.00%, 0:00:27.419685\n",
      "24.02%, 0:00:27.507148\n",
      "25.01%, 0:00:28.260021\n",
      "26.01%, 0:00:28.459636\n",
      "27.01%, 0:00:28.609696\n",
      "28.00%, 0:00:28.982101\n",
      "29.00%, 0:00:31.964525\n",
      "30.01%, 0:00:38.659893\n",
      "31.01%, 0:00:45.060946\n",
      "32.01%, 0:00:45.459746\n",
      "33.01%, 0:00:45.589665\n",
      "34.00%, 0:00:45.989717\n",
      "35.00%, 0:00:46.451412\n",
      "36.01%, 0:00:48.119802\n",
      "37.01%, 0:00:49.084986\n",
      "38.01%, 0:00:50.370050\n",
      "39.01%, 0:00:50.630044\n",
      "40.00%, 0:00:50.934903\n",
      "41.00%, 0:00:51.564686\n",
      "42.01%, 0:00:55.629821\n",
      "43.01%, 0:01:00.244702\n",
      "44.01%, 0:01:01.384697\n",
      "45.01%, 0:01:04.289793\n",
      "46.00%, 0:01:05.469598\n",
      "47.00%, 0:01:08.919586\n",
      "48.01%, 0:01:11.129810\n",
      "49.01%, 0:01:11.889612\n",
      "50.01%, 0:01:12.419884\n",
      "51.01%, 0:01:12.897553\n",
      "52.00%, 0:01:13.035037\n",
      "53.02%, 0:01:13.387856\n",
      "54.01%, 0:01:15.629955\n",
      "55.01%, 0:01:17.605098\n",
      "56.01%, 0:01:18.900675\n",
      "57.01%, 0:01:19.504766\n",
      "58.00%, 0:01:20.146004\n",
      "59.02%, 0:01:20.389943\n",
      "60.01%, 0:01:20.494080\n",
      "61.01%, 0:01:25.188165\n",
      "62.01%, 0:01:27.514777\n",
      "63.00%, 0:01:28.941363\n",
      "64.00%, 0:01:32.012623\n",
      "65.02%, 0:01:32.729705\n",
      "66.01%, 0:01:33.044670\n",
      "67.01%, 0:01:36.235955\n",
      "68.01%, 0:01:36.850019\n",
      "69.00%, 0:01:36.979548\n",
      "70.00%, 0:01:39.601542\n",
      "71.02%, 0:01:39.818195\n",
      "72.01%, 0:01:42.234407\n",
      "73.01%, 0:01:42.994940\n",
      "74.01%, 0:01:43.417932\n",
      "75.00%, 0:01:45.154256\n",
      "76.00%, 0:01:45.379420\n",
      "77.02%, 0:01:45.504293\n",
      "78.01%, 0:01:45.599643\n",
      "79.01%, 0:01:46.591908\n",
      "80.01%, 0:01:47.839637\n",
      "81.00%, 0:01:48.408354\n",
      "82.00%, 0:01:48.634760\n",
      "83.01%, 0:01:48.779789\n",
      "84.01%, 0:01:48.899626\n",
      "85.01%, 0:01:48.999788\n",
      "86.01%, 0:01:49.094759\n",
      "87.00%, 0:01:49.269698\n",
      "88.00%, 0:01:50.804608\n",
      "89.01%, 0:01:52.315599\n",
      "90.01%, 0:01:52.513371\n",
      "91.01%, 0:01:52.924853\n",
      "92.01%, 0:01:55.569460\n",
      "93.00%, 0:01:55.824571\n",
      "94.00%, 0:01:57.119592\n",
      "95.01%, 0:01:59.344611\n",
      "96.01%, 0:02:00.349527\n",
      "97.01%, 0:02:01.037687\n",
      "98.01%, 0:02:02.688682\n",
      "99.00%, 0:02:04.944829\n",
      "100.00%, 0:02:06.549435\n"
     ]
    }
   ],
   "source": [
    "# Figure out how many unique words are there in all playlists for all tracks\n",
    "global_words = []\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p=0\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "\n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    for w in unique_words:\n",
    "        if w not in global_words:\n",
    "            global_words.append(w)\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c374e195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373f0250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f3ca3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02%, 0:00:00.010489\n",
      "1.01%, 0:00:01.546749\n",
      "2.01%, 0:00:01.960900\n",
      "3.01%, 0:00:02.194353\n",
      "4.01%, 0:00:05.006599\n",
      "5.00%, 0:00:07.286426\n",
      "6.02%, 0:00:09.096407\n",
      "7.01%, 0:00:10.096814\n",
      "8.01%, 0:00:10.361572\n",
      "9.01%, 0:00:10.529722\n",
      "10.00%, 0:00:10.612038\n",
      "11.00%, 0:00:10.731634\n",
      "12.02%, 0:00:10.864116\n",
      "13.01%, 0:00:10.941842\n",
      "14.01%, 0:00:11.856625\n",
      "15.01%, 0:00:13.966449\n",
      "16.00%, 0:00:14.966417\n",
      "17.00%, 0:00:15.356609\n",
      "18.02%, 0:00:15.459257\n",
      "19.01%, 0:00:16.301833\n",
      "20.01%, 0:00:16.846726\n",
      "21.01%, 0:00:17.136560\n",
      "22.00%, 0:00:17.289049\n",
      "23.00%, 0:00:17.346434\n",
      "24.02%, 0:00:17.414357\n",
      "25.01%, 0:00:17.856483\n",
      "26.01%, 0:00:17.976553\n",
      "27.01%, 0:00:18.076595\n",
      "28.00%, 0:00:18.307344\n",
      "29.00%, 0:00:20.426807\n",
      "30.01%, 0:00:24.986584\n",
      "31.01%, 0:00:28.606618\n",
      "32.01%, 0:00:28.816729\n",
      "33.01%, 0:00:28.905305\n",
      "34.00%, 0:00:29.146725\n",
      "35.00%, 0:00:29.376691\n",
      "36.01%, 0:00:30.436389\n",
      "37.01%, 0:00:30.986712\n",
      "38.01%, 0:00:31.876352\n",
      "39.01%, 0:00:32.071427\n",
      "40.00%, 0:00:32.223536\n",
      "41.00%, 0:00:32.472158\n",
      "42.01%, 0:00:34.795618\n",
      "43.01%, 0:00:37.606353\n",
      "44.01%, 0:00:38.206458\n",
      "45.01%, 0:00:40.008370\n",
      "46.00%, 0:00:40.747560\n",
      "47.00%, 0:00:43.067582\n",
      "48.01%, 0:00:44.374347\n",
      "49.01%, 0:00:44.756694\n",
      "50.01%, 0:00:45.040968\n",
      "51.01%, 0:00:45.286358\n",
      "52.00%, 0:00:45.376363\n",
      "53.02%, 0:00:45.575763\n",
      "54.01%, 0:00:46.874134\n",
      "55.01%, 0:00:48.072349\n",
      "56.01%, 0:00:48.757553\n",
      "57.01%, 0:00:49.121459\n",
      "58.00%, 0:00:49.496482\n",
      "59.02%, 0:00:49.646617\n",
      "60.01%, 0:00:49.709845\n",
      "61.01%, 0:00:53.026657\n",
      "62.01%, 0:00:54.626429\n",
      "63.00%, 0:00:55.556600\n",
      "64.00%, 0:00:57.406561\n",
      "65.02%, 0:00:57.816717\n",
      "66.01%, 0:00:57.997433\n",
      "67.01%, 0:01:00.256505\n",
      "68.01%, 0:01:00.681380\n",
      "69.00%, 0:01:00.774108\n",
      "70.00%, 0:01:02.421409\n",
      "71.02%, 0:01:02.538385\n",
      "72.01%, 0:01:04.155742\n",
      "73.01%, 0:01:04.646418\n",
      "74.01%, 0:01:04.896511\n",
      "75.00%, 0:01:05.839959\n",
      "76.00%, 0:01:05.971355\n",
      "77.02%, 0:01:06.046384\n",
      "78.01%, 0:01:06.106436\n",
      "79.01%, 0:01:06.656569\n",
      "80.01%, 0:01:07.363174\n",
      "81.00%, 0:01:07.626480\n",
      "82.00%, 0:01:07.761444\n",
      "83.01%, 0:01:07.843358\n",
      "84.01%, 0:01:07.916577\n",
      "85.01%, 0:01:07.992743\n",
      "86.01%, 0:01:08.056564\n",
      "87.00%, 0:01:08.216404\n",
      "88.00%, 0:01:09.306350\n",
      "89.01%, 0:01:10.366655\n",
      "90.01%, 0:01:10.496528\n",
      "91.01%, 0:01:10.776418\n",
      "92.01%, 0:01:12.636387\n",
      "93.00%, 0:01:12.801825\n",
      "94.00%, 0:01:13.506245\n",
      "95.01%, 0:01:14.886514\n",
      "96.01%, 0:01:15.496489\n",
      "97.01%, 0:01:15.908213\n",
      "98.01%, 0:01:16.991691\n",
      "99.00%, 0:01:18.370445\n",
      "100.00%, 0:01:19.406500\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"global\": {},\n",
    "    \"track_id\":{}\n",
    "}\n",
    "for word in global_words:\n",
    "    data[\"global\"][word] = 0\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "total_rows = len(df['track_id'].unique())\n",
    "t = 0\n",
    "p = 0\n",
    "\n",
    "for track_id in df['track_id'].unique():\n",
    "    # get word bin counts for each track_id\n",
    "    # get clean playlist words\n",
    "    playlist_words = clean_playlist_names(track_id=track_id)\n",
    "    \n",
    "    # get unique playlist words\n",
    "    unique_words = set(playlist_words)\n",
    "\n",
    "    # create a dictionary with each unique word as a key with value = 0\n",
    "    data[\"track_id\"][track_id] = {}\n",
    "    for word in unique_words:\n",
    "        data[\"track_id\"][track_id][word] = 0\n",
    "    \n",
    "    # go through the clean playlist words and tabulate using the dictionary\n",
    "    # tally global words as well\n",
    "    for word in playlist_words:\n",
    "        data[\"track_id\"][track_id][word] += 1\n",
    "        data[\"global\"][word] += 1\n",
    "\n",
    "    t += 1\n",
    "    perc_complete = t*100/total_rows\n",
    "    if perc_complete >= p:\n",
    "        print(f'{perc_complete:.2f}%, {datetime.datetime.now()-start_time}')\n",
    "        p += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "02a9668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to a single json\n",
    "with open(\"word_count_data.json\",\"w\") as f:\n",
    "    json.dump(data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464e8c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
